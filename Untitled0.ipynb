{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0jwiORJ/dN62QjBlYrhQn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LotanLevy/DOC_/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRBtlfjZCDq"
      },
      "source": [
        "pip install tensorflow-gpu==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy_8DBwzbb-8",
        "outputId": "c067a236-ca0b-495d-e7dd-16ec3de45922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjNkU4uCbciS",
        "outputId": "4f662d33-cab0-4611-8d93-60c23bc854be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/LotanLevy/DOC_"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DOC_'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 174 (delta 104), reused 100 (delta 41), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (174/174), 59.39 KiB | 779.00 KiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tz6H8HmeHvb",
        "outputId": "f6123455-7dea-402a-ca49-75e11790f36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd DOC_/\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DOC_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCgRFCcaiOLY",
        "outputId": "5db82b0e-7cb7-4247-a07c-57a73add60f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea1KiVPveYb-",
        "outputId": "2bbaf220-1a31-42c2-e20c-1b60bbefad1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DOC_  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2oqa8GaTwEI"
      },
      "source": [
        "Standard train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2OI1bq5bo4O"
      },
      "source": [
        "!python train_main.py --name=\"l2_lamb_1_ref_imagnet\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJUrvcgiT3Jo"
      },
      "source": [
        "L1 train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBi4hk3rT0tp",
        "outputId": "7b5c890a-3090-4d18-809e-a73a6b2925bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_1_ref_imagnet_normal_var\" --c_loss_type=\"l1\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 1816/1816 [46:49<00:00,  1.55s/it]\n",
            "100% 1816/1816 [46:49<00:00,  1.55s/it]\n",
            "epoch: 1: d loss 1.4844287558869032, c loss 0.4043816705377945, accuracy 0.6530837004405287\n",
            "2020-10-20 11:06:35.577176: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [23:10<00:00,  1.31it/s]\n",
            "100% 1816/1816 [23:10<00:00,  1.31it/s]\n",
            "epoch: 2: d loss 1.408150830284986, c loss 0.23501505855561156, accuracy 0.6701541850220264\n",
            "2020-10-20 11:29:48.440477: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [21:09<00:00,  1.43it/s]\n",
            "100% 1816/1816 [21:09<00:00,  1.43it/s]\n",
            "epoch: 3: d loss 1.3917927995823252, c loss 0.16930466523960166, accuracy 0.6701541850220264\n",
            "2020-10-20 11:51:00.302259: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [18:17<00:00,  1.65it/s]\n",
            "100% 1816/1816 [18:17<00:00,  1.65it/s]\n",
            "epoch: 4: d loss 1.3416434709452096, c loss 0.13880622283132985, accuracy 0.6825440528634361\n",
            "2020-10-20 12:09:20.365450: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [17:34<00:00,  1.72it/s]\n",
            "100% 1816/1816 [17:34<00:00,  1.72it/s]\n",
            "epoch: 5: d loss 1.3461780984387395, c loss 0.11654711732977287, accuracy 0.6756607929515418\n",
            "2020-10-20 12:26:56.747247: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ai2iDnhTTH",
        "outputId": "7ce9f556-8962-40c4-f222-432f18e7c025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_0.5_ref_imagnet_normal_var\" --c_loss_type=\"l0.5\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-20 16:36:38.563663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Experiment dir and settings file created\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "Data files created\n",
            "l0.5 compactness loss initialized\n",
            "Model build...\n",
            "2020-10-20 16:36:48.446439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-20 16:36:48.477527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.478338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-20 16:36:48.478398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 16:36:48.480812: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 16:36:48.482773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 16:36:48.483543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 16:36:48.497598: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 16:36:48.498833: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 16:36:48.504170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 16:36:48.504397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.505300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.506111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 16:36:48.509784: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-10-20 16:36:48.516853: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-10-20 16:36:48.517134: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b3f9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 16:36:48.517176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-20 16:36:48.573501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.574341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b3fb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 16:36:48.574375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-10-20 16:36:48.574642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.575327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-20 16:36:48.575402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 16:36:48.575468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 16:36:48.575515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 16:36:48.575554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 16:36:48.575599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 16:36:48.575636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 16:36:48.575673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 16:36:48.575815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.576589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:48.577308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 16:36:48.577367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 16:36:49.137135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-20 16:36:49.137199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-20 16:36:49.137218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-20 16:36:49.137471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:49.138284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 16:36:49.139062: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-20 16:36:49.139131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 126,625,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 130,722,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "x_target is 3632 samples\n",
            "x_ref is 50000 samples\n",
            "training...\n",
            "  0% 0/1816 [00:00<?, ?it/s]2020-10-20 16:36:52.571083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 16:36:52.760027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "100% 1816/1816 [1:00:20<00:00,  1.99s/it]\n",
            "100% 1816/1816 [1:00:20<00:00,  1.99s/it]\n",
            "epoch: 1: d loss 1.5582306143797213, c loss 0.4374085041747679, accuracy 0.6316079295154186\n",
            "2020-10-20 17:37:11.418917: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [33:56<00:00,  1.12s/it]\n",
            "100% 1816/1816 [33:56<00:00,  1.12s/it]\n",
            "epoch: 2: d loss 1.4697707068423684, c loss 0.2105722814051656, accuracy 0.6588656387665198\n",
            "2020-10-20 18:11:11.484571: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [34:04<00:00,  1.13s/it]\n",
            "100% 1816/1816 [34:04<00:00,  1.13s/it]\n",
            "epoch: 3: d loss 1.4366023711014824, c loss 0.16301951980493176, accuracy 0.6599669603524229\n",
            "2020-10-20 18:45:17.761832: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [35:02<00:00,  1.16s/it]\n",
            "100% 1816/1816 [35:02<00:00,  1.16s/it]\n",
            "epoch: 4: d loss 1.3998119570706669, c loss 0.13730596588820163, accuracy 0.6723568281938326\n",
            "2020-10-20 19:20:22.860195: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "100% 1816/1816 [32:09<00:00,  1.06s/it]\n",
            "100% 1816/1816 [32:09<00:00,  1.06s/it]\n",
            "epoch: 5: d loss 1.389293088397678, c loss 0.11971057020794469, accuracy 0.6709801762114538\n",
            "2020-10-20 19:52:35.027758: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbn6v9QFi_0Z",
        "outputId": "38356d9d-599e-4650-f16e-f262aed387fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_0.2_ref_imagnet_normal_var\" --c_loss_type=\"l0.2\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-20 19:52:40.481700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Experiment dir and settings file created\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "Data files created\n",
            "l0.2 compactness loss initialized\n",
            "Model build...\n",
            "2020-10-20 19:52:46.435777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-20 19:52:46.461012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.461731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-20 19:52:46.461770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 19:52:46.463637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 19:52:46.465397: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 19:52:46.465750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 19:52:46.468212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 19:52:46.469806: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 19:52:46.476630: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 19:52:46.476777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.477752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.478583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 19:52:46.483098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-10-20 19:52:46.488888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-10-20 19:52:46.489156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x31919c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 19:52:46.489191: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-20 19:52:46.545885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.546777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3191b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 19:52:46.546816: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-10-20 19:52:46.547032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.547780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-20 19:52:46.547830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 19:52:46.547885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 19:52:46.547922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 19:52:46.547967: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 19:52:46.548012: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 19:52:46.548046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 19:52:46.548081: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 19:52:46.548205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.549042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:46.549820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 19:52:46.549879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 19:52:47.178085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-20 19:52:47.178144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-20 19:52:47.178161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-20 19:52:47.178536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:47.179545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 19:52:47.180288: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-20 19:52:47.180353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 126,625,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 130,722,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "x_target is 3632 samples\n",
            "x_ref is 50000 samples\n",
            "training...\n",
            "  0% 0/1816 [00:00<?, ?it/s]2020-10-20 19:52:51.175607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 19:52:51.352097: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            " 33% 603/1816 [13:09<26:28,  1.31s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"train_main.py\", line 52, in <module>\n",
            "    trainer.train()\n",
            "  File \"/content/DOC_/utils/experiment_utils.py\", line 113, in train\n",
            "    self.network_constractor, self.args.batchsize, self.args.target_layer, self.args.use_var_reg)\n",
            "  File \"/content/DOC_/train.py\", line 95, in train\n",
            "    lc.append(model_t.train_on_batch(batch_target, np.zeros((batchsize, 4096))))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1698, in train_on_batch\n",
            "    self.reset_metrics()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1637, in reset_metrics\n",
            "    m.reset_states()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\", line 247, in reset_states\n",
            "    K.batch_set_value([(v, 0) for v in self.variables])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
            "    return target(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\", line 3576, in batch_set_value\n",
            "    x.assign(np.asarray(value, dtype=dtype(x)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 860, in assign\n",
            "    self.handle, value_tensor, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 144, in assign_variable_op\n",
            "    tld.op_callbacks, resource, value)\n",
            "KeyboardInterrupt\n",
            " 33% 602/1816 [13:09<26:32,  1.31s/it]\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvXyf6B8hTcF",
        "outputId": "2fe7ec2b-eeba-43b1-c8a6-4351f15d8c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_0.08_ref_imagnet_normal_var\" --c_loss_type=\"l0.08\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-20 20:06:12.616722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Experiment dir and settings file created\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "Data files created\n",
            "l0.08 compactness loss initialized\n",
            "Model build...\n",
            "2020-10-20 20:06:16.816149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-20 20:06:16.835099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.835894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-20 20:06:16.835974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 20:06:16.837974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 20:06:16.840269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 20:06:16.840699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 20:06:16.842934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 20:06:16.843922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 20:06:16.847918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 20:06:16.848191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.848998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.849700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 20:06:16.852902: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-10-20 20:06:16.858851: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-10-20 20:06:16.859083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28a59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 20:06:16.859123: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-20 20:06:16.903540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.904369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28a5b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 20:06:16.904490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-10-20 20:06:16.904734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.905474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-20 20:06:16.905525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 20:06:16.905585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 20:06:16.905665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 20:06:16.905705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 20:06:16.905747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 20:06:16.905785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 20:06:16.905822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 20:06:16.905954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.906759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:16.907501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 20:06:16.907615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 20:06:17.447464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-20 20:06:17.447549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-20 20:06:17.447576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-20 20:06:17.447837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:17.448627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 20:06:17.449297: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-20 20:06:17.449347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 126,625,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 130,722,280\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "x_target is 3632 samples\n",
            "x_ref is 50000 samples\n",
            "training...\n",
            "  0% 0/1816 [00:00<?, ?it/s]2020-10-20 20:06:20.005632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 20:06:20.148701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "100% 1816/1816 [35:20<00:00,  1.17s/it]\n",
            "100% 1816/1816 [35:20<00:00,  1.17s/it]\n",
            "epoch: 1: d loss 1.566478209312599, c loss 0.4348507428127403, accuracy 0.6294052863436124\n",
            "2020-10-20 20:41:40.101342: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            " 89% 1615/1816 [23:36<02:24,  1.39it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ_3DtL7hTkZ",
        "outputId": "e80a50db-8446-47db-8d05-3bf05109c87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_0.05_ref_imagnet_normal_var\" --c_loss_type=\"l0.05\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-20 20:06:06.947374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Experiment dir and settings file created\n",
            "Traceback (most recent call last):\n",
            "  File \"train_main.py\", line 50, in <module>\n",
            "    trainer.set_ready()\n",
            "  File \"/content/DOC_/utils/experiment_utils.py\", line 92, in set_ready\n",
            "    alien_cls2label=alien_cls2label)\n",
            "  File \"/content/DOC_/dataloader.py\", line 196, in get_doc_loaders\n",
            "    preprocess_func=preprocess_func)\n",
            "  File \"/content/DOC_/dataloader.py\", line 168, in get_iterators_by_root_dir\n",
            "    for file in os.listdir(full_path):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO2gYo7NhdMZ"
      },
      "source": [
        "Reference data is now the target data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SLUBS5NhiCs"
      },
      "source": [
        "!python train_main.py --name=\"l2_lamb_1_ref_is_tar\" --cls_num=12 --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k--fYCMLG7CV"
      },
      "source": [
        "!python train_main.py --name=\"l2_lamb_0_ref_is_tar\" --lambda_=0 --cls_num=12 --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubesJARVHEe1"
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_0_ref_is_tar\" --lambda_=0 --c_loss_type=\"l1\" --cls_num=12 --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD1gjVMbbB3U"
      },
      "source": [
        "fc1 features layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXUzy8-VatE_"
      },
      "source": [
        "!python train_main.py --name=\"l2_lamb_1_ref_imagnet_features_is_fc1\" --target_layer=\"fc1\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvEc9EwvUEff"
      },
      "source": [
        "Augmented Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDmFyXf6hll8"
      },
      "source": [
        "!python preprocessing.py --images_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1el0cCn5TmnX"
      },
      "source": [
        "!python train_main.py --name=\"l2_lamb_1_ref_imagnet_tar_augment\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab_augmented\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hO8obsTykIo"
      },
      "source": [
        "Var reg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiG1KL41yleP"
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_1_var_reg_0.1_coeff\" --reg_coeff=0.1 --use_var_reg=1 --c_loss_type=\"l1\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHu2OI4vziP5"
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_1_var_reg_0.5_coeff\" --reg_coeff=0.5 --use_var_reg=1 --c_loss_type=\"l1\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vjRXdrezidA"
      },
      "source": [
        "!python train_main.py --name=\"l1_lamb_1_var_reg_1.0_coeff\" --reg_coeff=1.0 --use_var_reg=1 --c_loss_type=\"l1\" --ref_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/imagenet_val_splitted\" --tar_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_stab\" --alien_dir=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_aliens\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments\" --alien_cls2label=\"/content/drive/My Drive/Colab Notebooks/affordances/datasets/big_alien_splitted_cls2label.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNPWnXJY1Ttd"
      },
      "source": [
        "## **Tests**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwM6kbtO9IUE"
      },
      "source": [
        "Var regularization test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHz55f6b9OAz"
      },
      "source": [
        "!python test_main.py --name=\"var_regularization_comparisons\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_var_reg_0.1_coeff\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_var_reg_0.5_coeff\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_var_reg_1.0_coeff\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_ref_imagnet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_Qs_LQj9Zmg"
      },
      "source": [
        "l2 comprarison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1_oGJZj1S2o"
      },
      "source": [
        "!python test_main.py --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/untrained_l2_ref_imagenet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --name=\"l2_comparisons\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTKModib9dp6"
      },
      "source": [
        "l1 comparisons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKlKE9zH9ArR"
      },
      "source": [
        "!python test_main.py --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/untrained_l1_ref_imagenet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --name=\"l1_comparisons\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMb83WYGq9iW"
      },
      "source": [
        "!python test_main.py --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_ref_imagnet_normal_var\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --name=\"l1_comparisons_normal_and_not\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "029AN9xBzmjp"
      },
      "source": [
        "!python test_main.py --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l0.08_lamb_1_ref_imagnet_normal_var\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l0.05_lamb_1_ref_imagnet_normal_var\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l0.2_lamb_1_ref_imagnet_normal_var\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l0.5_lamb_1_ref_imagnet_normal_var\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_ref_imagnet_normal_var\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --name=\"l1_comparisons_normal\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i20M5kmLbmrR"
      },
      "source": [
        "Sparsity comparisons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdPcqQ1NbrJy",
        "outputId": "630e9d03-1142-4606-b744-409373d2ff56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python test_main.py --name=\"sparsity_comparisons\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_1_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_0.5_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_0.2_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_0.08_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l1_lamb_0.05_ref_imagnet\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-20 10:01:59.840936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "2020-10-20 10:02:03.234682: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-20 10:02:03.251476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.252428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-10-20 10:02:03.252480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 10:02:03.254239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 10:02:03.256015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 10:02:03.256442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 10:02:03.258187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 10:02:03.259641: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 10:02:03.263898: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 10:02:03.264043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.265035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.265902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 10:02:03.266418: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-10-20 10:02:03.272573: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-20 10:02:03.272855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b12f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 10:02:03.272893: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-20 10:02:03.369771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.371302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b13d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-20 10:02:03.371345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-10-20 10:02:03.371571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.372462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-10-20 10:02:03.372531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 10:02:03.372593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 10:02:03.372641: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-20 10:02:03.372691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-20 10:02:03.372757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-20 10:02:03.372805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-20 10:02:03.372855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-20 10:02:03.372955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.373876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:03.374856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-20 10:02:03.374940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-20 10:02:04.124890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-20 10:02:04.124947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-20 10:02:04.124969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-20 10:02:04.125212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:04.126121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-20 10:02:04.126973: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-20 10:02:04.127029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14951 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2020-10-20 10:02:05.961682: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "l1_lamb_1_ref_imagnet's ckpts loaded\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "2020-10-20 10:04:22.841925: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "l1_lamb_0.5_ref_imagnet's ckpts loaded\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "2020-10-20 10:05:29.573547: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "l1_lamb_0.2_ref_imagnet's ckpts loaded\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "2020-10-20 10:06:32.728547: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "l1_lamb_0.08_ref_imagnet's ckpts loaded\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '010': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '020': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '030': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '040': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '050': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '060': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '070': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '080': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '090': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '0100': 100, '0101': 101, '0102': 102, '0103': 103, '0104': 104, '0105': 105, '0106': 106, '0107': 107, '0108': 108, '0109': 109, '110': 110, '111': 111, '112': 112, '113': 113, '114': 114, '115': 115, '116': 116, '117': 117, '118': 118, '119': 119, '120': 120, '121': 121, '122': 122, '123': 123, '124': 124, '125': 125, '126': 126, '127': 127, '128': 128, '129': 129, '130': 130, '131': 131, '132': 132, '133': 133, '134': 134, '135': 135, '136': 136, '137': 137, '138': 138, '139': 139, '140': 140, '141': 141, '142': 142, '143': 143, '144': 144, '145': 145, '146': 146, '147': 147, '148': 148, '149': 149, '150': 150, '151': 151, '152': 152, '153': 153, '154': 154, '155': 155, '156': 156, '157': 157, '158': 158, '159': 159, '160': 160, '161': 161, '162': 162, '163': 163, '164': 164, '165': 165, '166': 166, '167': 167, '168': 168, '169': 169, '170': 170, '171': 171, '172': 172, '173': 173, '174': 174, '175': 175, '176': 176, '177': 177, '178': 178, '179': 179, '180': 180, '181': 181, '182': 182, '183': 183, '184': 184, '185': 185, '186': 186, '187': 187, '188': 188, '189': 189, '190': 190, '191': 191, '192': 192, '193': 193, '194': 194, '195': 195, '196': 196, '197': 197, '198': 198, '199': 199, '0200': 200, '0201': 201, '0202': 202, '0203': 203, '0204': 204, '0205': 205, '0206': 206, '0207': 207, '0208': 208, '0209': 209, '210': 210, '211': 211, '212': 212, '213': 213, '214': 214, '215': 215, '216': 216, '217': 217, '218': 218, '219': 219, '220': 220, '221': 221, '222': 222, '223': 223, '224': 224, '225': 225, '226': 226, '227': 227, '228': 228, '229': 229, '230': 230, '231': 231, '232': 232, '233': 233, '234': 234, '235': 235, '236': 236, '237': 237, '238': 238, '239': 239, '240': 240, '241': 241, '242': 242, '243': 243, '244': 244, '245': 245, '246': 246, '247': 247, '248': 248, '249': 249, '250': 250, '251': 251, '252': 252, '253': 253, '254': 254, '255': 255, '256': 256, '257': 257, '258': 258, '259': 259, '260': 260, '261': 261, '262': 262, '263': 263, '264': 264, '265': 265, '266': 266, '267': 267, '268': 268, '269': 269, '270': 270, '271': 271, '272': 272, '273': 273, '274': 274, '275': 275, '276': 276, '277': 277, '278': 278, '279': 279, '280': 280, '281': 281, '282': 282, '283': 283, '284': 284, '285': 285, '286': 286, '287': 287, '288': 288, '289': 289, '290': 290, '291': 291, '292': 292, '293': 293, '294': 294, '295': 295, '296': 296, '297': 297, '298': 298, '299': 299, '0300': 300, '0301': 301, '0302': 302, '0303': 303, '0304': 304, '0305': 305, '0306': 306, '0307': 307, '0308': 308, '0309': 309, '310': 310, '311': 311, '312': 312, '313': 313, '314': 314, '315': 315, '316': 316, '317': 317, '318': 318, '319': 319, '320': 320, '321': 321, '322': 322, '323': 323, '324': 324, '325': 325, '326': 326, '327': 327, '328': 328, '329': 329, '330': 330, '331': 331, '332': 332, '333': 333, '334': 334, '335': 335, '336': 336, '337': 337, '338': 338, '339': 339, '340': 340, '341': 341, '342': 342, '343': 343, '344': 344, '345': 345, '346': 346, '347': 347, '348': 348, '349': 349, '350': 350, '351': 351, '352': 352, '353': 353, '354': 354, '355': 355, '356': 356, '357': 357, '358': 358, '359': 359, '360': 360, '361': 361, '362': 362, '363': 363, '364': 364, '365': 365, '366': 366, '367': 367, '368': 368, '369': 369, '370': 370, '371': 371, '372': 372, '373': 373, '374': 374, '375': 375, '376': 376, '377': 377, '378': 378, '379': 379, '380': 380, '381': 381, '382': 382, '383': 383, '384': 384, '385': 385, '386': 386, '387': 387, '388': 388, '389': 389, '390': 390, '391': 391, '392': 392, '393': 393, '394': 394, '395': 395, '396': 396, '397': 397, '398': 398, '399': 399, '0400': 400, '0401': 401, '0402': 402, '0403': 403, '0404': 404, '0405': 405, '0406': 406, '0407': 407, '0408': 408, '0409': 409, '410': 410, '411': 411, '412': 412, '413': 413, '414': 414, '415': 415, '416': 416, '417': 417, '418': 418, '419': 419, '420': 420, '421': 421, '422': 422, '423': 423, '424': 424, '425': 425, '426': 426, '427': 427, '428': 428, '429': 429, '430': 430, '431': 431, '432': 432, '433': 433, '434': 434, '435': 435, '436': 436, '437': 437, '438': 438, '439': 439, '440': 440, '441': 441, '442': 442, '443': 443, '444': 444, '445': 445, '446': 446, '447': 447, '448': 448, '449': 449, '450': 450, '451': 451, '452': 452, '453': 453, '454': 454, '455': 455, '456': 456, '457': 457, '458': 458, '459': 459, '460': 460, '461': 461, '462': 462, '463': 463, '464': 464, '465': 465, '466': 466, '467': 467, '468': 468, '469': 469, '470': 470, '471': 471, '472': 472, '473': 473, '474': 474, '475': 475, '476': 476, '477': 477, '478': 478, '479': 479, '480': 480, '481': 481, '482': 482, '483': 483, '484': 484, '485': 485, '486': 486, '487': 487, '488': 488, '489': 489, '490': 490, '491': 491, '492': 492, '493': 493, '494': 494, '495': 495, '496': 496, '497': 497, '498': 498, '499': 499, '0500': 500, '0501': 501, '0502': 502, '0503': 503, '0504': 504, '0505': 505, '0506': 506, '0507': 507, '0508': 508, '0509': 509, '510': 510, '511': 511, '512': 512, '513': 513, '514': 514, '515': 515, '516': 516, '517': 517, '518': 518, '519': 519, '520': 520, '521': 521, '522': 522, '523': 523, '524': 524, '525': 525, '526': 526, '527': 527, '528': 528, '529': 529, '530': 530, '531': 531, '532': 532, '533': 533, '534': 534, '535': 535, '536': 536, '537': 537, '538': 538, '539': 539, '540': 540, '541': 541, '542': 542, '543': 543, '544': 544, '545': 545, '546': 546, '547': 547, '548': 548, '549': 549, '550': 550, '551': 551, '552': 552, '553': 553, '554': 554, '555': 555, '556': 556, '557': 557, '558': 558, '559': 559, '560': 560, '561': 561, '562': 562, '563': 563, '564': 564, '565': 565, '566': 566, '567': 567, '568': 568, '569': 569, '570': 570, '571': 571, '572': 572, '573': 573, '574': 574, '575': 575, '576': 576, '577': 577, '578': 578, '579': 579, '580': 580, '581': 581, '582': 582, '583': 583, '584': 584, '585': 585, '586': 586, '587': 587, '588': 588, '589': 589, '590': 590, '591': 591, '592': 592, '593': 593, '594': 594, '595': 595, '596': 596, '597': 597, '598': 598, '599': 599, '0600': 600, '0601': 601, '0602': 602, '0603': 603, '0604': 604, '0605': 605, '0606': 606, '0607': 607, '0608': 608, '0609': 609, '610': 610, '611': 611, '612': 612, '613': 613, '614': 614, '615': 615, '616': 616, '617': 617, '618': 618, '619': 619, '620': 620, '621': 621, '622': 622, '623': 623, '624': 624, '625': 625, '626': 626, '627': 627, '628': 628, '629': 629, '630': 630, '631': 631, '632': 632, '633': 633, '634': 634, '635': 635, '636': 636, '637': 637, '638': 638, '639': 639, '640': 640, '641': 641, '642': 642, '643': 643, '644': 644, '645': 645, '646': 646, '647': 647, '648': 648, '649': 649, '650': 650, '651': 651, '652': 652, '653': 653, '654': 654, '655': 655, '656': 656, '657': 657, '658': 658, '659': 659, '660': 660, '661': 661, '662': 662, '663': 663, '664': 664, '665': 665, '666': 666, '667': 667, '668': 668, '669': 669, '670': 670, '671': 671, '672': 672, '673': 673, '674': 674, '675': 675, '676': 676, '677': 677, '678': 678, '679': 679, '680': 680, '681': 681, '682': 682, '683': 683, '684': 684, '685': 685, '686': 686, '687': 687, '688': 688, '689': 689, '690': 690, '691': 691, '692': 692, '693': 693, '694': 694, '695': 695, '696': 696, '697': 697, '698': 698, '699': 699, '0700': 700, '0701': 701, '0702': 702, '0703': 703, '0704': 704, '0705': 705, '0706': 706, '0707': 707, '0708': 708, '0709': 709, '710': 710, '711': 711, '712': 712, '713': 713, '714': 714, '715': 715, '716': 716, '717': 717, '718': 718, '719': 719, '720': 720, '721': 721, '722': 722, '723': 723, '724': 724, '725': 725, '726': 726, '727': 727, '728': 728, '729': 729, '730': 730, '731': 731, '732': 732, '733': 733, '734': 734, '735': 735, '736': 736, '737': 737, '738': 738, '739': 739, '740': 740, '741': 741, '742': 742, '743': 743, '744': 744, '745': 745, '746': 746, '747': 747, '748': 748, '749': 749, '750': 750, '751': 751, '752': 752, '753': 753, '754': 754, '755': 755, '756': 756, '757': 757, '758': 758, '759': 759, '760': 760, '761': 761, '762': 762, '763': 763, '764': 764, '765': 765, '766': 766, '767': 767, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '773': 773, '774': 774, '775': 775, '776': 776, '777': 777, '778': 778, '779': 779, '780': 780, '781': 781, '782': 782, '783': 783, '784': 784, '785': 785, '786': 786, '787': 787, '788': 788, '789': 789, '790': 790, '791': 791, '792': 792, '793': 793, '794': 794, '795': 795, '796': 796, '797': 797, '798': 798, '799': 799, '0800': 800, '0801': 801, '0802': 802, '0803': 803, '0804': 804, '0805': 805, '0806': 806, '0807': 807, '0808': 808, '0809': 809, '810': 810, '811': 811, '812': 812, '813': 813, '814': 814, '815': 815, '816': 816, '817': 817, '818': 818, '819': 819, '820': 820, '821': 821, '822': 822, '823': 823, '824': 824, '825': 825, '826': 826, '827': 827, '828': 828, '829': 829, '830': 830, '831': 831, '832': 832, '833': 833, '834': 834, '835': 835, '836': 836, '837': 837, '838': 838, '839': 839, '840': 840, '841': 841, '842': 842, '843': 843, '844': 844, '845': 845, '846': 846, '847': 847, '848': 848, '849': 849, '850': 850, '851': 851, '852': 852, '853': 853, '854': 854, '855': 855, '856': 856, '857': 857, '858': 858, '859': 859, '860': 860, '861': 861, '862': 862, '863': 863, '864': 864, '865': 865, '866': 866, '867': 867, '868': 868, '869': 869, '870': 870, '871': 871, '872': 872, '873': 873, '874': 874, '875': 875, '876': 876, '877': 877, '878': 878, '879': 879, '880': 880, '881': 881, '882': 882, '883': 883, '884': 884, '885': 885, '886': 886, '887': 887, '888': 888, '889': 889, '890': 890, '891': 891, '892': 892, '893': 893, '894': 894, '895': 895, '896': 896, '897': 897, '898': 898, '899': 899, '0900': 900, '0901': 901, '0902': 902, '0903': 903, '0904': 904, '0905': 905, '0906': 906, '0907': 907, '0908': 908, '0909': 909, '910': 910, '911': 911, '912': 912, '913': 913, '914': 914, '915': 915, '916': 916, '917': 917, '918': 918, '919': 919, '920': 920, '921': 921, '922': 922, '923': 923, '924': 924, '925': 925, '926': 926, '927': 927, '928': 928, '929': 929, '930': 930, '931': 931, '932': 932, '933': 933, '934': 934, '935': 935, '936': 936, '937': 937, '938': 938, '939': 939, '940': 940, '941': 941, '942': 942, '943': 943, '944': 944, '945': 945, '946': 946, '947': 947, '948': 948, '949': 949, '950': 950, '951': 951, '952': 952, '953': 953, '954': 954, '955': 955, '956': 956, '957': 957, '958': 958, '959': 959, '960': 960, '961': 961, '962': 962, '963': 963, '964': 964, '965': 965, '966': 966, '967': 967, '968': 968, '969': 969, '970': 970, '971': 971, '972': 972, '973': 973, '974': 974, '975': 975, '976': 976, '977': 977, '978': 978, '979': 979, '980': 980, '981': 981, '982': 982, '983': 983, '984': 984, '985': 985, '986': 986, '987': 987, '988': 988, '989': 989, '990': 990, '991': 991, '992': 992, '993': 993, '994': 994, '995': 995, '996': 996, '997': 997, '998': 998, '999': 999}\n",
            "{'knife': 0, 'sword': 1, 'dagger': 2, 'pencil': 3, 'scissors': 4, 'iron nail': 5, 'swordfish': 6, 'toothpick': 7, 'tent_stake': 8, 'screwdriver': 9, 'garden_sickle': 10, 'letter opener': 11}\n",
            "classes in directory doesn't match classes_num\n",
            "{'cup': 0, 'pot': 0, 'fork': 0, 'cable': 0, 'chair': 0, 'plate': 0, 'spoon': 0, 'basket': 0, 'bow tie': 0, 'glasses': 0, 'eyeliner': 0, 'paper box': 0, 'basketball': 0, 'chopsticks': 0, 'drumsticks': 0, 'garden pot': 0, 'table lamp': 0, 'birtday hat': 0, 'sharp heels': 0, 'toilet paper': 0, 'icecream cone': 0, 'sharp screw': 1, 'letter opener': 1, 'syringe needle': 1, 'swordfish': 1, 'unicorn': 1, 'pencil': 1, 'scissors': 1, 'iron nail': 1, 'toothpick': 1, 'tent_stake': 1, 'closed_umbrella': 1, 'sword': 1, 'spear': 1, 'screwdriver': 1, 'knife': 1, 'garden_sickle': 1, 'dagger': 1}\n",
            "classes in directory doesn't match classes_num\n",
            "50000 0\n",
            "3632 909\n",
            "3786 0\n",
            "Network and dataloaders were created\n",
            "2020-10-20 10:07:29.766867: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of free system memory.\n",
            "l1_lamb_0.05_ref_imagnet's ckpts loaded\n",
            "2020-10-20 10:08:20.769109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-20 10:08:22.239647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "{'l1_lamb_1_ref_imagnet': 0.7403728365898132, 'l1_lamb_0.5_ref_imagnet': 0.3813258111476898, 'l1_lamb_0.2_ref_imagnet': 0.39291638135910034, 'l1_lamb_0.08_ref_imagnet': 0.41168156266212463, 'l1_lamb_0.05_ref_imagnet': 0.4446268081665039}\n",
            "tf.Tensor(0.23260657, shape=(), dtype=float32) [0.23260656]\n",
            "tf.Tensor(0.20362611, shape=(), dtype=float32) [0.20362611]\n",
            "tf.Tensor(0.21153422, shape=(), dtype=float32) [0.21153429]\n",
            "tf.Tensor(0.24230663, shape=(), dtype=float32) [0.24230663]\n",
            "tf.Tensor(0.272641, shape=(), dtype=float32) [0.272641]\n",
            "tf.Tensor(0.09659635, shape=(), dtype=float32) [0.09659635]\n",
            "tf.Tensor(0.09143091, shape=(), dtype=float32) [0.09143092]\n",
            "tf.Tensor(0.09575946, shape=(), dtype=float32) [0.09575953]\n",
            "tf.Tensor(0.15225141, shape=(), dtype=float32) [0.15225144]\n",
            "tf.Tensor(0.17039889, shape=(), dtype=float32) [0.17039888]\n",
            "tf.Tensor(0.35630924, shape=(), dtype=float32) [0.35630918]\n",
            "tf.Tensor(0.21514185, shape=(), dtype=float32) [0.21514186]\n",
            "tf.Tensor(0.22013023, shape=(), dtype=float32) [0.22013029]\n",
            "tf.Tensor(0.24089527, shape=(), dtype=float32) [0.24089527]\n",
            "tf.Tensor(0.26146495, shape=(), dtype=float32) [0.26146495]\n",
            "tf.Tensor(0.4518052, shape=(), dtype=float32) [0.45180517]\n",
            "tf.Tensor(0.29739437, shape=(), dtype=float32) [0.29739442]\n",
            "tf.Tensor(0.3025835, shape=(), dtype=float32) [0.30258355]\n",
            "tf.Tensor(0.33210555, shape=(), dtype=float32) [0.33210555]\n",
            "tf.Tensor(0.3532496, shape=(), dtype=float32) [0.35324961]\n",
            "tf.Tensor(0.06924154, shape=(), dtype=float32) [0.06924153]\n",
            "tf.Tensor(0.07703064, shape=(), dtype=float32) [0.07703066]\n",
            "tf.Tensor(0.07477529, shape=(), dtype=float32) [0.07477535]\n",
            "tf.Tensor(0.1290441, shape=(), dtype=float32) [0.12904413]\n",
            "tf.Tensor(0.15751833, shape=(), dtype=float32) [0.1575183]\n",
            "tf.Tensor(0.42098117, shape=(), dtype=float32) [0.42098111]\n",
            "tf.Tensor(0.28914654, shape=(), dtype=float32) [0.28914657]\n",
            "tf.Tensor(0.3055945, shape=(), dtype=float32) [0.30559453]\n",
            "tf.Tensor(0.3247612, shape=(), dtype=float32) [0.32476121]\n",
            "tf.Tensor(0.34500584, shape=(), dtype=float32) [0.34500581]\n",
            "tf.Tensor(0.3000215, shape=(), dtype=float32) [0.3000215]\n",
            "tf.Tensor(0.20387666, shape=(), dtype=float32) [0.20387669]\n",
            "tf.Tensor(0.22261532, shape=(), dtype=float32) [0.22261536]\n",
            "tf.Tensor(0.24687521, shape=(), dtype=float32) [0.24687524]\n",
            "tf.Tensor(0.26467696, shape=(), dtype=float32) [0.26467696]\n",
            "tf.Tensor(0.21906242, shape=(), dtype=float32) [0.21906242]\n",
            "tf.Tensor(0.15197031, shape=(), dtype=float32) [0.15197036]\n",
            "tf.Tensor(0.15655515, shape=(), dtype=float32) [0.15655522]\n",
            "tf.Tensor(0.19925803, shape=(), dtype=float32) [0.19925806]\n",
            "tf.Tensor(0.20483908, shape=(), dtype=float32) [0.20483908]\n",
            "tf.Tensor(0.114996254, shape=(), dtype=float32) [0.11499625]\n",
            "tf.Tensor(0.10747752, shape=(), dtype=float32) [0.10747752]\n",
            "tf.Tensor(0.111868225, shape=(), dtype=float32) [0.1118683]\n",
            "tf.Tensor(0.16398135, shape=(), dtype=float32) [0.16398163]\n",
            "tf.Tensor(0.19661623, shape=(), dtype=float32) [0.1966162]\n",
            "tf.Tensor(0.53171575, shape=(), dtype=float32) [0.53171575]\n",
            "tf.Tensor(0.3808627, shape=(), dtype=float32) [0.38086271]\n",
            "tf.Tensor(0.3929165, shape=(), dtype=float32) [0.3929165]\n",
            "tf.Tensor(0.41168156, shape=(), dtype=float32) [0.41168156]\n",
            "tf.Tensor(0.44462687, shape=(), dtype=float32) [0.44462681]\n",
            "tf.Tensor(0.18135388, shape=(), dtype=float32) [0.18135385]\n",
            "tf.Tensor(0.16373675, shape=(), dtype=float32) [0.16373676]\n",
            "tf.Tensor(0.16754258, shape=(), dtype=float32) [0.16754262]\n",
            "tf.Tensor(0.24067798, shape=(), dtype=float32) [0.24067803]\n",
            "tf.Tensor(0.2813682, shape=(), dtype=float32) [0.2813682]\n",
            "tf.Tensor(0.74037266, shape=(), dtype=float32) [0.74037266]\n",
            "tf.Tensor(0.38132566, shape=(), dtype=float32) [0.38132566]\n",
            "tf.Tensor(0.3836244, shape=(), dtype=float32) [0.38362446]\n",
            "tf.Tensor(0.37967592, shape=(), dtype=float32) [0.37967598]\n",
            "tf.Tensor(0.38546342, shape=(), dtype=float32) [0.38546342]\n",
            "tf.Tensor(0.11866782, shape=(), dtype=float32) [0.11866782]\n",
            "tf.Tensor(0.12416081, shape=(), dtype=float32) [0.12416083]\n",
            "tf.Tensor(0.12424878, shape=(), dtype=float32) [0.12424885]\n",
            "tf.Tensor(0.1817175, shape=(), dtype=float32) [0.1817175]\n",
            "tf.Tensor(0.20423782, shape=(), dtype=float32) [0.20423782]\n",
            "tf.Tensor(0.2630961, shape=(), dtype=float32) [0.26309609]\n",
            "tf.Tensor(0.20432107, shape=(), dtype=float32) [0.2043211]\n",
            "tf.Tensor(0.20948605, shape=(), dtype=float32) [0.20948613]\n",
            "tf.Tensor(0.24064343, shape=(), dtype=float32) [0.24064343]\n",
            "tf.Tensor(0.2841631, shape=(), dtype=float32) [0.28416306]\n",
            "tf.Tensor(0.121546365, shape=(), dtype=float32) [0.12154637]\n",
            "tf.Tensor(0.12186841, shape=(), dtype=float32) [0.12186837]\n",
            "tf.Tensor(0.11707407, shape=(), dtype=float32) [0.11707413]\n",
            "tf.Tensor(0.18432951, shape=(), dtype=float32) [0.18432951]\n",
            "tf.Tensor(0.21305342, shape=(), dtype=float32) [0.21305358]\n",
            "tf.Tensor(0.38308683, shape=(), dtype=float32) [0.38308683]\n",
            "tf.Tensor(0.22321498, shape=(), dtype=float32) [0.22321501]\n",
            "tf.Tensor(0.22610848, shape=(), dtype=float32) [0.22610846]\n",
            "tf.Tensor(0.24581571, shape=(), dtype=float32) [0.24581566]\n",
            "tf.Tensor(0.260485, shape=(), dtype=float32) [0.26048499]\n",
            "tf.Tensor(0.3148176, shape=(), dtype=float32) [0.31481758]\n",
            "tf.Tensor(0.19650002, shape=(), dtype=float32) [0.19650003]\n",
            "tf.Tensor(0.20422189, shape=(), dtype=float32) [0.20422189]\n",
            "tf.Tensor(0.2285842, shape=(), dtype=float32) [0.22858422]\n",
            "tf.Tensor(0.25303516, shape=(), dtype=float32) [0.25303522]\n",
            "tf.Tensor(0.085435905, shape=(), dtype=float32) [0.0854359]\n",
            "tf.Tensor(0.07646333, shape=(), dtype=float32) [0.07646334]\n",
            "tf.Tensor(0.07963344, shape=(), dtype=float32) [0.07963351]\n",
            "tf.Tensor(0.12589025, shape=(), dtype=float32) [0.12589025]\n",
            "tf.Tensor(0.1578254, shape=(), dtype=float32) [0.15782537]\n",
            "tf.Tensor(0.198674, shape=(), dtype=float32) [0.19867399]\n",
            "tf.Tensor(0.12906499, shape=(), dtype=float32) [0.12906501]\n",
            "tf.Tensor(0.1297228, shape=(), dtype=float32) [0.12972286]\n",
            "tf.Tensor(0.17897253, shape=(), dtype=float32) [0.17897253]\n",
            "tf.Tensor(0.19021976, shape=(), dtype=float32) [0.19021976]\n",
            "tf.Tensor(0.11543193, shape=(), dtype=float32) [0.11543193]\n",
            "tf.Tensor(0.11755069, shape=(), dtype=float32) [0.11755071]\n",
            "tf.Tensor(0.11791112, shape=(), dtype=float32) [0.11791117]\n",
            "tf.Tensor(0.17149566, shape=(), dtype=float32) [0.17149568]\n",
            "tf.Tensor(0.20202331, shape=(), dtype=float32) [0.2020233]\n",
            "tf.Tensor(0.1123199, shape=(), dtype=float32) [0.1123199]\n",
            "tf.Tensor(0.10912989, shape=(), dtype=float32) [0.10912988]\n",
            "tf.Tensor(0.11494587, shape=(), dtype=float32) [0.11494593]\n",
            "tf.Tensor(0.16397503, shape=(), dtype=float32) [0.16397503]\n",
            "tf.Tensor(0.18194102, shape=(), dtype=float32) [0.18194103]\n",
            "tf.Tensor(0.29586738, shape=(), dtype=float32) [0.29586738]\n",
            "tf.Tensor(0.20887217, shape=(), dtype=float32) [0.20887217]\n",
            "tf.Tensor(0.20321612, shape=(), dtype=float32) [0.20321622]\n",
            "tf.Tensor(0.24437733, shape=(), dtype=float32) [0.24437734]\n",
            "tf.Tensor(0.25318855, shape=(), dtype=float32) [0.25318855]\n",
            "tf.Tensor(0.118468724, shape=(), dtype=float32) [0.11846872]\n",
            "tf.Tensor(0.12133614, shape=(), dtype=float32) [0.12133615]\n",
            "tf.Tensor(0.12255095, shape=(), dtype=float32) [0.12255096]\n",
            "tf.Tensor(0.18087809, shape=(), dtype=float32) [0.18087812]\n",
            "tf.Tensor(0.21881072, shape=(), dtype=float32) [0.21881071]\n",
            "tf.Tensor(0.24258113, shape=(), dtype=float32) [0.2425811]\n",
            "tf.Tensor(0.17849095, shape=(), dtype=float32) [0.17849097]\n",
            "tf.Tensor(0.18709207, shape=(), dtype=float32) [0.18709219]\n",
            "tf.Tensor(0.22919555, shape=(), dtype=float32) [0.22919555]\n",
            "tf.Tensor(0.26287138, shape=(), dtype=float32) [0.26287138]\n",
            "tf.Tensor(0.0784065, shape=(), dtype=float32) [0.0784065]\n",
            "tf.Tensor(0.08422704, shape=(), dtype=float32) [0.08422704]\n",
            "tf.Tensor(0.083974704, shape=(), dtype=float32) [0.08397476]\n",
            "tf.Tensor(0.13716939, shape=(), dtype=float32) [0.13716941]\n",
            "tf.Tensor(0.1672391, shape=(), dtype=float32) [0.16723908]\n",
            "tf.Tensor(0.29211617, shape=(), dtype=float32) [0.29211617]\n",
            "tf.Tensor(0.18000928, shape=(), dtype=float32) [0.18000932]\n",
            "tf.Tensor(0.19538137, shape=(), dtype=float32) [0.19538143]\n",
            "tf.Tensor(0.23254201, shape=(), dtype=float32) [0.23254204]\n",
            "tf.Tensor(0.25549158, shape=(), dtype=float32) [0.25549158]\n",
            "tf.Tensor(0.10627502, shape=(), dtype=float32) [0.10627502]\n",
            "tf.Tensor(0.12959796, shape=(), dtype=float32) [0.12959798]\n",
            "tf.Tensor(0.13413051, shape=(), dtype=float32) [0.13413045]\n",
            "tf.Tensor(0.19355169, shape=(), dtype=float32) [0.19355169]\n",
            "tf.Tensor(0.21615636, shape=(), dtype=float32) [0.21615633]\n",
            "tf.Tensor(0.14154534, shape=(), dtype=float32) [0.14154533]\n",
            "tf.Tensor(0.11063351, shape=(), dtype=float32) [0.11063353]\n",
            "tf.Tensor(0.10954632, shape=(), dtype=float32) [0.10954639]\n",
            "tf.Tensor(0.1680078, shape=(), dtype=float32) [0.16800782]\n",
            "tf.Tensor(0.18932645, shape=(), dtype=float32) [0.18932644]\n",
            "tf.Tensor(0.256311, shape=(), dtype=float32) [0.256311]\n",
            "tf.Tensor(0.16822357, shape=(), dtype=float32) [0.16822362]\n",
            "tf.Tensor(0.19476953, shape=(), dtype=float32) [0.19476955]\n",
            "tf.Tensor(0.23204987, shape=(), dtype=float32) [0.23204987]\n",
            "tf.Tensor(0.25387713, shape=(), dtype=float32) [0.25387713]\n",
            "tf.Tensor(0.28008705, shape=(), dtype=float32) [0.28008705]\n",
            "tf.Tensor(0.21988022, shape=(), dtype=float32) [0.21988025]\n",
            "tf.Tensor(0.22888109, shape=(), dtype=float32) [0.22888112]\n",
            "tf.Tensor(0.25856227, shape=(), dtype=float32) [0.25856227]\n",
            "tf.Tensor(0.28348112, shape=(), dtype=float32) [0.28348115]\n",
            "tf.Tensor(0.13139595, shape=(), dtype=float32) [0.13139594]\n",
            "tf.Tensor(0.09148278, shape=(), dtype=float32) [0.0914828]\n",
            "tf.Tensor(0.0932859, shape=(), dtype=float32) [0.09328597]\n",
            "tf.Tensor(0.1391708, shape=(), dtype=float32) [0.1391708]\n",
            "tf.Tensor(0.162805, shape=(), dtype=float32) [0.16280499]\n",
            "tf.Tensor(0.17769828, shape=(), dtype=float32) [0.17769825]\n",
            "tf.Tensor(0.121424936, shape=(), dtype=float32) [0.12142496]\n",
            "tf.Tensor(0.12728706, shape=(), dtype=float32) [0.12728712]\n",
            "tf.Tensor(0.16830406, shape=(), dtype=float32) [0.16830406]\n",
            "tf.Tensor(0.19845667, shape=(), dtype=float32) [0.19845667]\n",
            "tf.Tensor(0.11586229, shape=(), dtype=float32) [0.11586229]\n",
            "tf.Tensor(0.09117691, shape=(), dtype=float32) [0.09117693]\n",
            "tf.Tensor(0.09329, shape=(), dtype=float32) [0.09329005]\n",
            "tf.Tensor(0.13930352, shape=(), dtype=float32) [0.13930352]\n",
            "tf.Tensor(0.1623111, shape=(), dtype=float32) [0.16231108]\n",
            "tf.Tensor(0.14767465, shape=(), dtype=float32) [0.14767464]\n",
            "tf.Tensor(0.1292208, shape=(), dtype=float32) [0.12922081]\n",
            "tf.Tensor(0.13606843, shape=(), dtype=float32) [0.13606854]\n",
            "tf.Tensor(0.18567713, shape=(), dtype=float32) [0.18567711]\n",
            "tf.Tensor(0.20356151, shape=(), dtype=float32) [0.2035615]\n",
            "tf.Tensor(0.2618476, shape=(), dtype=float32) [0.26184765]\n",
            "tf.Tensor(0.1825892, shape=(), dtype=float32) [0.1825892]\n",
            "tf.Tensor(0.18378365, shape=(), dtype=float32) [0.18378372]\n",
            "tf.Tensor(0.22979954, shape=(), dtype=float32) [0.22979954]\n",
            "tf.Tensor(0.2412293, shape=(), dtype=float32) [0.2412293]\n",
            "tf.Tensor(0.4242755, shape=(), dtype=float32) [0.42427549]\n",
            "tf.Tensor(0.18702051, shape=(), dtype=float32) [0.18702053]\n",
            "tf.Tensor(0.19473442, shape=(), dtype=float32) [0.19473448]\n",
            "tf.Tensor(0.21334481, shape=(), dtype=float32) [0.21334484]\n",
            "tf.Tensor(0.21834712, shape=(), dtype=float32) [0.21834712]\n",
            "tf.Tensor(0.08322233, shape=(), dtype=float32) [0.08322232]\n",
            "tf.Tensor(0.08767106, shape=(), dtype=float32) [0.08767107]\n",
            "tf.Tensor(0.090551555, shape=(), dtype=float32) [0.0905516]\n",
            "tf.Tensor(0.147404, shape=(), dtype=float32) [0.147404]\n",
            "tf.Tensor(0.1708713, shape=(), dtype=float32) [0.17087129]\n",
            "tf.Tensor(0.1297495, shape=(), dtype=float32) [0.12974951]\n",
            "tf.Tensor(0.14249621, shape=(), dtype=float32) [0.14249621]\n",
            "tf.Tensor(0.14583573, shape=(), dtype=float32) [0.1458358]\n",
            "tf.Tensor(0.2118729, shape=(), dtype=float32) [0.21187294]\n",
            "tf.Tensor(0.26669663, shape=(), dtype=float32) [0.26669675]\n",
            "tf.Tensor(0.11134106, shape=(), dtype=float32) [0.11134104]\n",
            "tf.Tensor(0.11128907, shape=(), dtype=float32) [0.11128908]\n",
            "tf.Tensor(0.114645384, shape=(), dtype=float32) [0.11464546]\n",
            "tf.Tensor(0.1721168, shape=(), dtype=float32) [0.1721168]\n",
            "tf.Tensor(0.19445318, shape=(), dtype=float32) [0.19445316]\n",
            "tf.Tensor(0.109978005, shape=(), dtype=float32) [0.10997801]\n",
            "tf.Tensor(0.08721723, shape=(), dtype=float32) [0.08721724]\n",
            "tf.Tensor(0.0922006, shape=(), dtype=float32) [0.09220067]\n",
            "tf.Tensor(0.13958326, shape=(), dtype=float32) [0.13958327]\n",
            "tf.Tensor(0.16963267, shape=(), dtype=float32) [0.16963264]\n",
            "tf.Tensor(0.114943825, shape=(), dtype=float32) [0.11494382]\n",
            "tf.Tensor(0.127377, shape=(), dtype=float32) [0.12737702]\n",
            "tf.Tensor(0.13539243, shape=(), dtype=float32) [0.1353925]\n",
            "tf.Tensor(0.1880891, shape=(), dtype=float32) [0.1880891]\n",
            "tf.Tensor(0.22010496, shape=(), dtype=float32) [0.2201049]\n",
            "tf.Tensor(0.4311533, shape=(), dtype=float32) [0.4311533]\n",
            "tf.Tensor(0.23609734, shape=(), dtype=float32) [0.23609737]\n",
            "tf.Tensor(0.2310864, shape=(), dtype=float32) [0.2310864]\n",
            "tf.Tensor(0.25331154, shape=(), dtype=float32) [0.25331157]\n",
            "tf.Tensor(0.29145834, shape=(), dtype=float32) [0.29145834]\n",
            "tf.Tensor(0.1232392, shape=(), dtype=float32) [0.1232392]\n",
            "tf.Tensor(0.12100451, shape=(), dtype=float32) [0.12100451]\n",
            "tf.Tensor(0.12564003, shape=(), dtype=float32) [0.12564009]\n",
            "tf.Tensor(0.1909078, shape=(), dtype=float32) [0.19090782]\n",
            "tf.Tensor(0.23170587, shape=(), dtype=float32) [0.2317059]\n",
            "tf.Tensor(0.12482433, shape=(), dtype=float32) [0.12482433]\n",
            "tf.Tensor(0.10346843, shape=(), dtype=float32) [0.10346844]\n",
            "tf.Tensor(0.110697486, shape=(), dtype=float32) [0.11069755]\n",
            "tf.Tensor(0.16076286, shape=(), dtype=float32) [0.16076286]\n",
            "tf.Tensor(0.18514124, shape=(), dtype=float32) [0.18514124]\n",
            "tf.Tensor(0.076380774, shape=(), dtype=float32) [0.07638077]\n",
            "tf.Tensor(0.07866998, shape=(), dtype=float32) [0.07866999]\n",
            "tf.Tensor(0.07862745, shape=(), dtype=float32) [0.0786275]\n",
            "tf.Tensor(0.13371073, shape=(), dtype=float32) [0.13371083]\n",
            "tf.Tensor(0.1660794, shape=(), dtype=float32) [0.16607937]\n",
            "tf.Tensor(0.44537425, shape=(), dtype=float32) [0.44537425]\n",
            "tf.Tensor(0.29503405, shape=(), dtype=float32) [0.29503405]\n",
            "tf.Tensor(0.310071, shape=(), dtype=float32) [0.31007105]\n",
            "tf.Tensor(0.32740492, shape=(), dtype=float32) [0.32740492]\n",
            "tf.Tensor(0.3421756, shape=(), dtype=float32) [0.3421756]\n",
            "tf.Tensor(0.45650095, shape=(), dtype=float32) [0.45650095]\n",
            "tf.Tensor(0.26914698, shape=(), dtype=float32) [0.26914698]\n",
            "tf.Tensor(0.2745785, shape=(), dtype=float32) [0.27457851]\n",
            "tf.Tensor(0.28790933, shape=(), dtype=float32) [0.28790939]\n",
            "tf.Tensor(0.30684322, shape=(), dtype=float32) [0.30684328]\n",
            "tf.Tensor(0.106172025, shape=(), dtype=float32) [0.10617201]\n",
            "tf.Tensor(0.09220161, shape=(), dtype=float32) [0.09220163]\n",
            "tf.Tensor(0.09273461, shape=(), dtype=float32) [0.09273466]\n",
            "tf.Tensor(0.14259334, shape=(), dtype=float32) [0.14259343]\n",
            "tf.Tensor(0.16588186, shape=(), dtype=float32) [0.16588184]\n",
            "tf.Tensor(0.1811592, shape=(), dtype=float32) [0.18115918]\n",
            "tf.Tensor(0.13337518, shape=(), dtype=float32) [0.1333752]\n",
            "tf.Tensor(0.14372614, shape=(), dtype=float32) [0.1437262]\n",
            "tf.Tensor(0.18769315, shape=(), dtype=float32) [0.18769315]\n",
            "tf.Tensor(0.20128699, shape=(), dtype=float32) [0.20128699]\n",
            "tf.Tensor(0.20298369, shape=(), dtype=float32) [0.20298369]\n",
            "tf.Tensor(0.16712281, shape=(), dtype=float32) [0.16712281]\n",
            "tf.Tensor(0.16802093, shape=(), dtype=float32) [0.16802096]\n",
            "tf.Tensor(0.213611, shape=(), dtype=float32) [0.21361101]\n",
            "tf.Tensor(0.24825203, shape=(), dtype=float32) [0.24825203]\n",
            "tf.Tensor(0.13669729, shape=(), dtype=float32) [0.13669729]\n",
            "tf.Tensor(0.10649569, shape=(), dtype=float32) [0.10649572]\n",
            "tf.Tensor(0.11763225, shape=(), dtype=float32) [0.11763231]\n",
            "tf.Tensor(0.15734902, shape=(), dtype=float32) [0.15734902]\n",
            "tf.Tensor(0.20123658, shape=(), dtype=float32) [0.20123656]\n",
            "tf.Tensor(0.18726781, shape=(), dtype=float32) [0.18726778]\n",
            "tf.Tensor(0.14328992, shape=(), dtype=float32) [0.14328995]\n",
            "tf.Tensor(0.15218762, shape=(), dtype=float32) [0.15218754]\n",
            "tf.Tensor(0.19187427, shape=(), dtype=float32) [0.1918743]\n",
            "tf.Tensor(0.21222658, shape=(), dtype=float32) [0.21222658]\n",
            "tf.Tensor(0.3721803, shape=(), dtype=float32) [0.37218031]\n",
            "tf.Tensor(0.28140765, shape=(), dtype=float32) [0.28140768]\n",
            "tf.Tensor(0.28740418, shape=(), dtype=float32) [0.28740415]\n",
            "tf.Tensor(0.31412068, shape=(), dtype=float32) [0.3141208]\n",
            "tf.Tensor(0.34192276, shape=(), dtype=float32) [0.34192276]\n",
            "tf.Tensor(0.103703275, shape=(), dtype=float32) [0.10370328]\n",
            "tf.Tensor(0.08919379, shape=(), dtype=float32) [0.08919381]\n",
            "tf.Tensor(0.09298076, shape=(), dtype=float32) [0.09298081]\n",
            "tf.Tensor(0.14415309, shape=(), dtype=float32) [0.14415307]\n",
            "tf.Tensor(0.16526125, shape=(), dtype=float32) [0.16526125]\n",
            "tf.Tensor(0.21672186, shape=(), dtype=float32) [0.21672186]\n",
            "tf.Tensor(0.13326888, shape=(), dtype=float32) [0.13326898]\n",
            "tf.Tensor(0.14222732, shape=(), dtype=float32) [0.14222737]\n",
            "tf.Tensor(0.18013668, shape=(), dtype=float32) [0.18013671]\n",
            "tf.Tensor(0.21607606, shape=(), dtype=float32) [0.21607618]\n",
            "tf.Tensor(0.22385554, shape=(), dtype=float32) [0.22385554]\n",
            "tf.Tensor(0.19529912, shape=(), dtype=float32) [0.19529912]\n",
            "tf.Tensor(0.2044659, shape=(), dtype=float32) [0.20446596]\n",
            "tf.Tensor(0.24995378, shape=(), dtype=float32) [0.24995379]\n",
            "tf.Tensor(0.27209342, shape=(), dtype=float32) [0.27209342]\n",
            "tf.Tensor(0.10098265, shape=(), dtype=float32) [0.10098265]\n",
            "tf.Tensor(0.10629217, shape=(), dtype=float32) [0.1062922]\n",
            "tf.Tensor(0.10918115, shape=(), dtype=float32) [0.10918119]\n",
            "tf.Tensor(0.16732654, shape=(), dtype=float32) [0.16732654]\n",
            "tf.Tensor(0.19751479, shape=(), dtype=float32) [0.19751477]\n",
            "tf.Tensor(0.24354573, shape=(), dtype=float32) [0.24354573]\n",
            "tf.Tensor(0.18544842, shape=(), dtype=float32) [0.18544842]\n",
            "tf.Tensor(0.1918733, shape=(), dtype=float32) [0.19187339]\n",
            "tf.Tensor(0.22795561, shape=(), dtype=float32) [0.22795558]\n",
            "tf.Tensor(0.2599851, shape=(), dtype=float32) [0.25998509]\n",
            "tf.Tensor(0.5994832, shape=(), dtype=float32) [0.59948319]\n",
            "tf.Tensor(0.29464483, shape=(), dtype=float32) [0.29464483]\n",
            "tf.Tensor(0.30085793, shape=(), dtype=float32) [0.30085796]\n",
            "tf.Tensor(0.31190205, shape=(), dtype=float32) [0.31190205]\n",
            "tf.Tensor(0.32799825, shape=(), dtype=float32) [0.32799831]\n",
            "tf.Tensor(0.118711375, shape=(), dtype=float32) [0.11871137]\n",
            "tf.Tensor(0.12696406, shape=(), dtype=float32) [0.12696408]\n",
            "tf.Tensor(0.12577762, shape=(), dtype=float32) [0.12577768]\n",
            "tf.Tensor(0.17782214, shape=(), dtype=float32) [0.17782214]\n",
            "tf.Tensor(0.21130595, shape=(), dtype=float32) [0.21130595]\n",
            "tf.Tensor(0.13867335, shape=(), dtype=float32) [0.13867334]\n",
            "tf.Tensor(0.11326434, shape=(), dtype=float32) [0.11326434]\n",
            "tf.Tensor(0.11278801, shape=(), dtype=float32) [0.11278807]\n",
            "tf.Tensor(0.160006, shape=(), dtype=float32) [0.16000603]\n",
            "tf.Tensor(0.19026157, shape=(), dtype=float32) [0.19026154]\n",
            "tf.Tensor(0.3251692, shape=(), dtype=float32) [0.32516918]\n",
            "tf.Tensor(0.22352064, shape=(), dtype=float32) [0.22352064]\n",
            "tf.Tensor(0.22306581, shape=(), dtype=float32) [0.22306582]\n",
            "tf.Tensor(0.26483074, shape=(), dtype=float32) [0.26483074]\n",
            "tf.Tensor(0.27000073, shape=(), dtype=float32) [0.27000073]\n",
            "tf.Tensor(0.54502237, shape=(), dtype=float32) [0.54502237]\n",
            "tf.Tensor(0.319403, shape=(), dtype=float32) [0.31940299]\n",
            "tf.Tensor(0.3298007, shape=(), dtype=float32) [0.32980078]\n",
            "tf.Tensor(0.33893818, shape=(), dtype=float32) [0.33893815]\n",
            "tf.Tensor(0.35680944, shape=(), dtype=float32) [0.35680944]\n",
            "tf.Tensor(0.14737493, shape=(), dtype=float32) [0.14737491]\n",
            "tf.Tensor(0.105331466, shape=(), dtype=float32) [0.10533147]\n",
            "tf.Tensor(0.107484564, shape=(), dtype=float32) [0.10748458]\n",
            "tf.Tensor(0.15647808, shape=(), dtype=float32) [0.15647809]\n",
            "tf.Tensor(0.17263536, shape=(), dtype=float32) [0.17263535]\n",
            "tf.Tensor(0.45170823, shape=(), dtype=float32) [0.45170823]\n",
            "tf.Tensor(0.21826744, shape=(), dtype=float32) [0.21826744]\n",
            "tf.Tensor(0.2307935, shape=(), dtype=float32) [0.23079355]\n",
            "tf.Tensor(0.2443552, shape=(), dtype=float32) [0.2443552]\n",
            "tf.Tensor(0.26240402, shape=(), dtype=float32) [0.26240402]\n",
            "tf.Tensor(0.120107114, shape=(), dtype=float32) [0.1201071]\n",
            "tf.Tensor(0.11036017, shape=(), dtype=float32) [0.11036018]\n",
            "tf.Tensor(0.1113316, shape=(), dtype=float32) [0.11133168]\n",
            "tf.Tensor(0.16482612, shape=(), dtype=float32) [0.16482614]\n",
            "tf.Tensor(0.19366112, shape=(), dtype=float32) [0.19366112]\n",
            "tf.Tensor(0.0858816, shape=(), dtype=float32) [0.08588159]\n",
            "tf.Tensor(0.084296964, shape=(), dtype=float32) [0.08429697]\n",
            "tf.Tensor(0.08676078, shape=(), dtype=float32) [0.08676088]\n",
            "tf.Tensor(0.14130501, shape=(), dtype=float32) [0.14130506]\n",
            "tf.Tensor(0.16865222, shape=(), dtype=float32) [0.16865221]\n",
            "tf.Tensor(0.110978566, shape=(), dtype=float32) [0.11097856]\n",
            "tf.Tensor(0.097931385, shape=(), dtype=float32) [0.0979314]\n",
            "tf.Tensor(0.10472777, shape=(), dtype=float32) [0.10472784]\n",
            "tf.Tensor(0.16315079, shape=(), dtype=float32) [0.16315079]\n",
            "tf.Tensor(0.18199347, shape=(), dtype=float32) [0.18199347]\n",
            "tf.Tensor(0.16746311, shape=(), dtype=float32) [0.16746309]\n",
            "tf.Tensor(0.15242556, shape=(), dtype=float32) [0.15242556]\n",
            "tf.Tensor(0.15260106, shape=(), dtype=float32) [0.15260114]\n",
            "tf.Tensor(0.20938928, shape=(), dtype=float32) [0.2093893]\n",
            "tf.Tensor(0.22205381, shape=(), dtype=float32) [0.22205377]\n",
            "tf.Tensor(0.2111835, shape=(), dtype=float32) [0.2111835]\n",
            "tf.Tensor(0.19436362, shape=(), dtype=float32) [0.19436362]\n",
            "tf.Tensor(0.20257592, shape=(), dtype=float32) [0.20257592]\n",
            "tf.Tensor(0.26146072, shape=(), dtype=float32) [0.26146072]\n",
            "tf.Tensor(0.2864517, shape=(), dtype=float32) [0.28645167]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFqod9kq98LR"
      },
      "source": [
        "Features comparisons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EVK-6cx96hZ"
      },
      "source": [
        "!python test_main.py --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/untrained_l2_features_is_f1\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet_features_is_fc1\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --name=\"features_comparisons\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QprDmBkr-IVi"
      },
      "source": [
        "reference data comparisons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNQqd-xa-Hup"
      },
      "source": [
        "!python test_main.py --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_imagnet\" --models_dirs=\"/content/drive/My Drive/Colab Notebooks/affordances/experiments/l2_lamb_1_ref_is_tar\" --output_path=\"/content/drive/My Drive/Colab Notebooks/affordances/doc_test_results\" --name=\"reference_data_comparisons\" --cam_grads_images --scores_graph --target2alien_roc --alien2alien_roc "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}